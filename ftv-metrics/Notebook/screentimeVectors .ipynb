{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from operator import itemgetter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "refPath = \"/Users/amira/Desktop/corpus_stt/medias_corrected/fr-FR_news_0120be6c-7b6d-447a-bae2-d79a9149ddd6_Journal-Polynesie/reference_transcript_to_evaluate.json\"\n",
    "hypPath = \"/Users/amira/Desktop/corpus_stt/medias_corrected/fr-FR_news_0120be6c-7b6d-447a-bae2-d79a9149ddd6_Journal-Polynesie/vocapia/nlp_transcript_norm.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to read a transcript json file\n",
    "def read_transcript(transcriptPath):\n",
    "    try:\n",
    "        return json.load(open(transcriptPath,'rt',encoding='utf-8'))\n",
    "    except FileNotFoundError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to get the speaker time intervals\n",
    "def get_speaker_screen_time(transcript):\n",
    "    speakers = transcript['speakers']\n",
    "    words = transcript['words']\n",
    "    speakerScreenTimeList = []\n",
    "    \n",
    "    for speaker in speakers : \n",
    "\n",
    "        speakerId = speaker['id']\n",
    "        speakerScreenTime =[]\n",
    "        \n",
    "        interList = []\n",
    "        i = 0\n",
    "        while i < len(words):\n",
    "            interList = []\n",
    "            while i < len(words) and words[i]['speakerId'] == speakerId:\n",
    "                interList.append(words[i])\n",
    "                i+=1\n",
    "            \n",
    "            if len(interList) > 0 :\n",
    "                screenTime = {\n",
    "                    \"startTime\" : interList[0]['startTime'],\n",
    "                    \"endTime\" : interList[-1]['endTime']\n",
    "                }\n",
    "                speakerScreenTime.append(screenTime)\n",
    "                interList = []\n",
    "            else :\n",
    "                i+=1\n",
    "\n",
    "        \n",
    "        speaker['speakerScreenTime'] = speakerScreenTime\n",
    "        speakerScreenTimeList.append(speaker)\n",
    "                    \n",
    "    return speakerScreenTimeList\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaker_vector(speakerId, screenTime, totalTime, silenceList):\n",
    "    speakerList = [0]*(totalTime + 1)\n",
    "    \n",
    "    for timeSlot in screenTime:\n",
    "        \n",
    "        startTime = int(timeSlot[\"startTime\"])\n",
    "        endTime = int(timeSlot['endTime'])\n",
    "        for i in range(startTime, endTime + 1, 1):\n",
    "            speakerList[i] = 1\n",
    "            silenceList[i] = 0\n",
    "    \n",
    "    return speakerList, silenceList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_speaker_arrays(speakerScreenTime, totalTime):\n",
    "    listSpeakers = []\n",
    "    silenceList = [1]*(totalTime + 1)\n",
    "    for elem in screenTime:\n",
    "        speakerList, silenceList = get_speaker_vector(elem['id'], elem[\"speakerScreenTime\"], totalTime, silenceList)\n",
    "        listSpeakers.append(speakerList)\n",
    "\n",
    "    listSpeakers = [silenceList] + listSpeakers\n",
    "    return np.array(listSpeakers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypTranscript = read_transcript(hypPath)\n",
    "refTranscript = read_transcript(refPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypSpeakerScreenTime = get_speaker_screen_time(hypTranscript)\n",
    "refSpeakerScreenTime = get_speaker_screen_time(refTranscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalRefTime =  int(refTranscript['words'][-1]['endTime'])\n",
    "totalHypTime =  int(hypTranscript['words'][-1]['endTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'screenTime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-4ff183344daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhypRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilt_speaker_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypSpeakerScreenTime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalHypTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrefRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilt_speaker_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefSpeakerScreenTime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalRefTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-9fbaa9c50194>\u001b[0m in \u001b[0;36mbuilt_speaker_arrays\u001b[0;34m(speakerScreenTime, totalTime)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlistSpeakers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msilenceList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalTime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscreenTime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mspeakerList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilenceList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_speaker_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"speakerScreenTime\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalTime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilenceList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mlistSpeakers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeakerList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'screenTime' is not defined"
     ]
    }
   ],
   "source": [
    "hypRes = built_speaker_arrays(hypSpeakerScreenTime, totalHypTime)\n",
    "refRes = built_speaker_arrays(refSpeakerScreenTime, totalRefTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
